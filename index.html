<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Textbook from the Future</title>
  <link rel="stylesheet" href="styles.css">
  <link rel="icon" type="image/png" href="images/t-favicon-96.png" sizes="96x96">
</head>
<body>
  <nav class="site-nav">
    <a href="index.html" class="active">Vision</a>
    <a href="projects.html">Projects</a>
    <a href="join.html">Join Us</a>
    <a href="faq.html">FAQ</a>
  </nav>
  <p class="quote">
    The metaphor I usually use is that if a <strong>textbook from one hundred years in the future</strong> fell into our hands, containing all of the simple ideas that actually work robustly in practice, we could probably build an aligned super&#8209;intelligence in six months.
    <br><span class="attribution">â€” Eliezer Yudkowsky</span>
  </p>
  <!-- <h1>Book structure</h1>
  <h2>Volume 1: Foundations</h2>
  <p>
    This volume introduces the core conceptual underpinnings for understanding intelligence and alignment. It explores how foundational concepts like abstraction, causality, compositionality, simplicity, degeneracy, learning and value have been formalised across disciplines, and how they are used to understanding intelligent systems.
  </p>
  <h2>Volume 2: Learning, Inference, and Interpretability</h2>
  <p>
    This volume focuses on the formal frameworks used to understand how AI systems learn and how they operate. It covers advanced topics such as singular learning theory, computational mechanics, and the inductive biases of AI models, explaining how we can analyze and interpret their internal workings.
  </p>
  <h2>Volume 3: Agency</h2>
  <p>
    This volume leverages the contents of previous volumes to develop a theory of agency, focusing on how intelligent behavior emerges from simple components. It explores the transition from basic elements to complex agents, covering decision theory, embedded agency, and the role of reinforcement learning and its underlying assumptions for creating agents.
  </p>
  <h2>Volume 4: Alignment</h2>
  <p>
    This volume addresses the problem of AI alignment building up in the understanding established by previous volumes. It covers the challenges of aligning superintelligent machines, formalizing the problems of (mis)alignment and specifying in detail failure modes of naive alignment protocols. It ends with protocols for controlling and directing superintelligent AI.
  </p> -->
  <footer class="site-footer">
    <a href="mailto:alexander.medronho@gmail.com">Contact</a>
  </footer>
</body>
</html>


